{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8. Postagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8Y4rZN1hyPBq+HhofaZLX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u85UNd59aNx",
        "colab_type": "text"
      },
      "source": [
        "Melakukan pengkatogorian kelas kata, seperti kata benda, kata kerja, kata sifat, dll\n",
        "\n",
        "Reference : https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UZE_4g50v9x",
        "colab_type": "text"
      },
      "source": [
        "# Menggunakan NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zuyPwr13KPX",
        "colab_type": "code",
        "outputId": "d3127efd-d92c-4ca9-c59a-c6490c1e1140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import nltk #import library nltk\n",
        "from nltk.tokenize import word_tokenize #import word_tokenize for tokenizing text into words\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHd1job-31-r",
        "colab_type": "code",
        "outputId": "516c3587-d311-4ec6-911c-d133027b9b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kalimat_1 = \"My name is Dede Brahma\"\n",
        "token = nltk.word_tokenize(kalimat_1)\n",
        "token"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My', 'name', 'is', 'Dede', 'Brahma']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My', 'name', 'is', 'Dede', 'Brahma']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG7Y4foM34mp",
        "colab_type": "code",
        "outputId": "f615b1bf-4607-493f-9fd4-09329236a29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "nltk.pos_tag(token)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('My', 'PRP$'),\n",
              " ('name', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('Dede', 'NNP'),\n",
              " ('Brahma', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('My', 'PRP$'),\n",
              " ('name', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('Dede', 'NNP'),\n",
              " ('Brahma', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yfv53ac4Gcx",
        "colab_type": "code",
        "outputId": "7578742b-bd02-4488-881e-cc61ebb9ea22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "kalimat_2 = \"the little yellow dog barked at the cat\"\n",
        "grammar = ('''\n",
        "      NP: {<DT>?<JJ>*<NN>} # NP\n",
        "      ''')\n",
        "chunkParser = nltk.RegexpParser(grammar)\n",
        "tagged = nltk.pos_tag(nltk.word_tokenize(kalimat_2))\n",
        "tagged"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('little', 'JJ'),\n",
              " ('yellow', 'JJ'),\n",
              " ('dog', 'NN'),\n",
              " ('barked', 'VBD'),\n",
              " ('at', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('cat', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('little', 'JJ'),\n",
              " ('yellow', 'JJ'),\n",
              " ('dog', 'NN'),\n",
              " ('barked', 'VBD'),\n",
              " ('at', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('cat', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX4CtMbe4kqW",
        "colab_type": "code",
        "outputId": "78a2610c-7d9a-4bd6-cb59-075cdac1be55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "tree = chunkParser.parse(tagged)\n",
        "for subtree in tree.subtrees():\n",
        "  print(subtree)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
            "  barked/VBD\n",
            "  at/IN\n",
            "  (NP the/DT cat/NN))\n",
            "(NP the/DT little/JJ yellow/JJ dog/NN)\n",
            "(NP the/DT cat/NN)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghas_e6p3Xs1",
        "colab_type": "code",
        "outputId": "c80a9e91-9849-4417-b919-8d1dce9c4482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "#pos tagging\n",
        "def postag(str):\n",
        "    tok_sentence = nltk.word_tokenize(str)\n",
        "    tagged_sentence = nltk.pos_tag(tok_sentence)\n",
        "    return tagged_sentence\n",
        "\n",
        "text_data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms\"\n",
        "postag(text_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('It', 'PRP'),\n",
              " ('originated', 'VBD'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('idea', 'NN'),\n",
              " ('that', 'IN'),\n",
              " ('there', 'EX'),\n",
              " ('are', 'VBP'),\n",
              " ('readers', 'NNS'),\n",
              " ('who', 'WP'),\n",
              " ('prefer', 'VBP'),\n",
              " ('learning', 'VBG'),\n",
              " ('new', 'JJ'),\n",
              " ('skills', 'NNS'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('comforts', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('their', 'PRP$'),\n",
              " ('drawing', 'NN'),\n",
              " ('rooms', 'NNS')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('It', 'PRP'),\n",
              " ('originated', 'VBD'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('idea', 'NN'),\n",
              " ('that', 'IN'),\n",
              " ('there', 'EX'),\n",
              " ('are', 'VBP'),\n",
              " ('readers', 'NNS'),\n",
              " ('who', 'WP'),\n",
              " ('prefer', 'VBP'),\n",
              " ('learning', 'VBG'),\n",
              " ('new', 'JJ'),\n",
              " ('skills', 'NNS'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('comforts', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('their', 'PRP$'),\n",
              " ('drawing', 'NN'),\n",
              " ('rooms', 'NNS')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNoCawUi0z6C",
        "colab_type": "text"
      },
      "source": [
        "# Menggunakan Flair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-KW2dgd03A7",
        "colab_type": "text"
      },
      "source": [
        "Reference : https://github.com/flairNLP/flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkss76Es7rfO",
        "colab_type": "code",
        "outputId": "98dd94f3-3c00-4d7a-9fc0-8b1a39d7b9b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install flair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/29/81e3c9a829ec50857c23d82560941625f6b42ce76ee7c56ea9529e959d18/flair-0.4.5-py3-none-any.whl (136kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.4.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 14.7MB/s \n",
            "\u001b[?25hCollecting transformers>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 21.8MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Collecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/e2/c19c667f42f72716a7d03e8dd4d6f63f47d39feadd44cc1ee7ca3089862c/pytest-5.4.1-py3-none-any.whl (246kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 22.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.18.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 22.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (1.12.18)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.5.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.1.8)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (45.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (1.15.18)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.3.0->flair) (7.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.18->boto3->transformers>=2.3.0->flair) (0.15.2)\n",
            "Building wheels for collected packages: sqlitedict, mpld3, segtok, langdetect, sacremoses\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=77ebf94462857e0f7b36290dc72f0d0a7477a16c591a0b29816072fc62294cd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=2ad40d611cbcbc73bd62c34d49d464fed8aadfab5e9ecadba7195e47f1312d57\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=6c85664c408d5f0a252e9bb8f32107784d8d95819959a519b5b0c8db38aa0acf\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=8c9df67e3a05a55cb19ada24859e814813dfa4985e7484ca3c4a5cdc8f029b6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=16627fd7233c2861e03c96a12ea6cd017cca8953e2b1ddf340d9890e0cee5c85\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sqlitedict mpld3 segtok langdetect sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sqlitedict, mpld3, deprecated, segtok, langdetect, tokenizers, sentencepiece, sacremoses, transformers, bpemb, pluggy, pytest, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.7 flair-0.4.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.1 sacremoses-0.0.38 segtok-1.5.7 sentencepiece-0.1.85 sqlitedict-1.6.0 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70fy04EW7v4Z",
        "colab_type": "code",
        "outputId": "7d6f080d-4b8d-4664-ee7f-9f6a35c98afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, BertEmbeddings\n",
        "from typing import List"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxFJ78Vzz884",
        "colab_type": "code",
        "outputId": "1ba87c00-2a6d-4b17-f382-42714fa5c840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 1. get the corpus\n",
        "corpus = NLPTaskDataFetcher.load_corpus(NLPTask.UD_INDONESIAN)\n",
        "\n",
        "# 2. what tag do we want to predict?\n",
        "tag_type = 'upos'\n",
        "\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "print(tag_dictionary.idx2item)\n",
        "\n",
        "# 4. initialize embeddings\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "    WordEmbeddings('id-crawl'),\n",
        "    WordEmbeddings('id'),\n",
        "    #WordEmbeddings('glove'),\n",
        "    #BertEmbeddings('bert-base-multilingual-cased')\n",
        "]\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# 5. initialize sequence tagger\n",
        "from flair.models import SequenceTagger\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type,\n",
        "                                        use_crf=True)\n",
        "\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train('resources/taggers/example-universal-pos',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) load_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:04,589 https://raw.githubusercontent.com/UniversalDependencies/UD_Indonesian-GSD/master/id_gsd-ud-dev.conllu not found in cache, downloading to /tmp/tmpdev8uvyx\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "979367B [00:00, 18901996.26B/s]          "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:04,717 copying /tmp/tmpdev8uvyx to cache at /root/.flair/datasets/ud_indonesian/id_gsd-ud-dev.conllu\n",
            "2020-03-17 14:06:04,719 removing temp file /tmp/tmpdev8uvyx\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:05,013 https://raw.githubusercontent.com/UniversalDependencies/UD_Indonesian-GSD/master/id_gsd-ud-test.conllu not found in cache, downloading to /tmp/tmpudpmfe9r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "916721B [00:00, 22473721.61B/s]          "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:05,294 copying /tmp/tmpudpmfe9r to cache at /root/.flair/datasets/ud_indonesian/id_gsd-ud-test.conllu\n",
            "2020-03-17 14:06:05,300 removing temp file /tmp/tmpudpmfe9r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:05,606 https://raw.githubusercontent.com/UniversalDependencies/UD_Indonesian-GSD/master/id_gsd-ud-train.conllu not found in cache, downloading to /tmp/tmpkyrtiqyf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7591261B [00:00, 62547011.10B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:06,232 copying /tmp/tmpkyrtiqyf to cache at /root/.flair/datasets/ud_indonesian/id_gsd-ud-train.conllu\n",
            "2020-03-17 14:06:06,246 removing temp file /tmp/tmpkyrtiqyf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:06,347 Reading data from /root/.flair/datasets/ud_indonesian\n",
            "2020-03-17 14:06:06,348 Train: /root/.flair/datasets/ud_indonesian/id_gsd-ud-train.conllu\n",
            "2020-03-17 14:06:06,349 Dev: /root/.flair/datasets/ud_indonesian/id_gsd-ud-dev.conllu\n",
            "2020-03-17 14:06:06,350 Test: /root/.flair/datasets/ud_indonesian/id_gsd-ud-test.conllu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:225: DeprecationWarning: Call to deprecated function (or staticmethod) load_ud_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  return NLPTaskDataFetcher.load_ud_corpus(data_folder)\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:391: DeprecationWarning: Call to deprecated function (or staticmethod) read_conll_ud. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  sentences_train: List[Sentence] = NLPTaskDataFetcher.read_conll_ud(train_file)\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:392: DeprecationWarning: Call to deprecated function (or staticmethod) read_conll_ud. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  sentences_test: List[Sentence] = NLPTaskDataFetcher.read_conll_ud(test_file)\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:393: DeprecationWarning: Call to deprecated function (or staticmethod) read_conll_ud. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  sentences_dev: List[Sentence] = NLPTaskDataFetcher.read_conll_ud(dev_file)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[b'<unk>', b'O', b'PROPN', b'AUX', b'DET', b'NOUN', b'PRON', b'VERB', b'ADP', b'PUNCT', b'ADV', b'CCONJ', b'SCONJ', b'NUM', b'ADJ', b'PART', b'SYM', b'X', b'<START>', b'<STOP>']\n",
            "2020-03-17 14:06:10,031 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/id-crawl-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmplofdgno_\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1199998928/1199998928 [00:43<00:00, 27300468.71B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:54,526 copying /tmp/tmplofdgno_ to cache at /root/.flair/embeddings/id-crawl-fasttext-300d-1M.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:06:58,859 removing temp file /tmp/tmplofdgno_\n",
            "2020-03-17 14:06:59,491 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/id-crawl-fasttext-300d-1M not found in cache, downloading to /tmp/tmpu5yadq29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 39636845/39636845 [00:02<00:00, 16143729.07B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:07:02,489 copying /tmp/tmpu5yadq29 to cache at /root/.flair/embeddings/id-crawl-fasttext-300d-1M\n",
            "2020-03-17 14:07:02,528 removing temp file /tmp/tmpu5yadq29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:07:07,395 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/id-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmp4hfj3wjx\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 360822128/360822128 [00:13<00:00, 27717886.19B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:07:21,067 copying /tmp/tmp4hfj3wjx to cache at /root/.flair/embeddings/id-wiki-fasttext-300d-1M.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:07:22,269 removing temp file /tmp/tmp4hfj3wjx\n",
            "2020-03-17 14:07:22,785 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/id-wiki-fasttext-300d-1M not found in cache, downloading to /tmp/tmp2wpbycua\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11638719/11638719 [00:01<00:00, 9521246.47B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:07:24,502 copying /tmp/tmp2wpbycua to cache at /root/.flair/embeddings/id-wiki-fasttext-300d-1M\n",
            "2020-03-17 14:07:24,516 removing temp file /tmp/tmp2wpbycua\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:07:26,042 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:07:26,046 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('id-crawl')\n",
            "    (list_embedding_1): WordEmbeddings('id')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=600, out_features=600, bias=True)\n",
            "  (rnn): LSTM(600, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-03-17 14:07:26,047 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:07:26,048 Corpus: \"Corpus: 4477 train + 559 dev + 557 test sentences\"\n",
            "2020-03-17 14:07:26,050 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:07:26,050 Parameters:\n",
            "2020-03-17 14:07:26,052  - learning_rate: \"0.1\"\n",
            "2020-03-17 14:07:26,052  - mini_batch_size: \"32\"\n",
            "2020-03-17 14:07:26,053  - patience: \"3\"\n",
            "2020-03-17 14:07:26,054  - anneal_factor: \"0.5\"\n",
            "2020-03-17 14:07:26,055  - max_epochs: \"10\"\n",
            "2020-03-17 14:07:26,056  - shuffle: \"True\"\n",
            "2020-03-17 14:07:26,057  - train_with_dev: \"False\"\n",
            "2020-03-17 14:07:26,058  - batch_growth_annealing: \"False\"\n",
            "2020-03-17 14:07:26,059 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:07:26,060 Model training base path: \"resources/taggers/example-universal-pos\"\n",
            "2020-03-17 14:07:26,061 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:07:26,063 Device: cpu\n",
            "2020-03-17 14:07:26,064 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:07:26,065 Embeddings storage mode: cpu\n",
            "2020-03-17 14:07:26,066 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:07:36,147 epoch 1 - iter 14/140 - loss 63.09166282 - samples/sec: 44.53\n",
            "2020-03-17 14:07:46,040 epoch 1 - iter 28/140 - loss 54.53586769 - samples/sec: 45.34\n",
            "2020-03-17 14:07:55,462 epoch 1 - iter 42/140 - loss 48.63676466 - samples/sec: 47.60\n",
            "2020-03-17 14:08:05,778 epoch 1 - iter 56/140 - loss 44.38619637 - samples/sec: 43.47\n",
            "2020-03-17 14:08:16,250 epoch 1 - iter 70/140 - loss 41.24909870 - samples/sec: 42.81\n",
            "2020-03-17 14:08:26,697 epoch 1 - iter 84/140 - loss 38.70971721 - samples/sec: 42.93\n",
            "2020-03-17 14:08:37,950 epoch 1 - iter 98/140 - loss 36.59690328 - samples/sec: 39.85\n",
            "2020-03-17 14:08:48,690 epoch 1 - iter 112/140 - loss 34.77407314 - samples/sec: 41.76\n",
            "2020-03-17 14:08:57,814 epoch 1 - iter 126/140 - loss 33.07870312 - samples/sec: 49.15\n",
            "2020-03-17 14:09:05,950 epoch 1 - iter 140/140 - loss 31.46200088 - samples/sec: 55.13\n",
            "2020-03-17 14:09:05,959 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:09:05,960 EPOCH 1 done: loss 31.4620 - lr 0.1000\n",
            "2020-03-17 14:09:09,201 DEV : loss 13.474578857421875 - score 0.808\n",
            "2020-03-17 14:09:09,253 BAD EPOCHS (no improvement): 0\n",
            "2020-03-17 14:09:27,568 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:09:38,184 epoch 2 - iter 14/140 - loss 16.37389660 - samples/sec: 42.21\n",
            "2020-03-17 14:09:48,609 epoch 2 - iter 28/140 - loss 16.38985491 - samples/sec: 43.01\n",
            "2020-03-17 14:09:58,832 epoch 2 - iter 42/140 - loss 16.00145090 - samples/sec: 43.86\n",
            "2020-03-17 14:10:10,617 epoch 2 - iter 56/140 - loss 15.87906650 - samples/sec: 38.05\n",
            "2020-03-17 14:10:20,395 epoch 2 - iter 70/140 - loss 15.70519266 - samples/sec: 45.86\n",
            "2020-03-17 14:10:29,594 epoch 2 - iter 84/140 - loss 15.35807015 - samples/sec: 48.75\n",
            "2020-03-17 14:10:38,893 epoch 2 - iter 98/140 - loss 15.09485256 - samples/sec: 48.23\n",
            "2020-03-17 14:10:49,695 epoch 2 - iter 112/140 - loss 14.93500513 - samples/sec: 41.51\n",
            "2020-03-17 14:10:59,785 epoch 2 - iter 126/140 - loss 14.79564590 - samples/sec: 44.44\n",
            "2020-03-17 14:11:08,326 epoch 2 - iter 140/140 - loss 14.51837623 - samples/sec: 52.52\n",
            "2020-03-17 14:11:08,336 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:11:08,337 EPOCH 2 done: loss 14.5184 - lr 0.1000\n",
            "2020-03-17 14:11:11,379 DEV : loss 8.728076934814453 - score 0.8708\n",
            "2020-03-17 14:11:11,434 BAD EPOCHS (no improvement): 0\n",
            "2020-03-17 14:11:27,466 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:11:35,785 epoch 3 - iter 14/140 - loss 11.66114834 - samples/sec: 53.87\n",
            "2020-03-17 14:11:44,631 epoch 3 - iter 28/140 - loss 11.87004147 - samples/sec: 50.71\n",
            "2020-03-17 14:11:55,237 epoch 3 - iter 42/140 - loss 11.86321947 - samples/sec: 42.28\n",
            "2020-03-17 14:12:07,389 epoch 3 - iter 56/140 - loss 11.88517569 - samples/sec: 36.90\n",
            "2020-03-17 14:12:17,691 epoch 3 - iter 70/140 - loss 11.80983692 - samples/sec: 43.53\n",
            "2020-03-17 14:12:33,272 epoch 3 - iter 84/140 - loss 11.76213259 - samples/sec: 28.77\n",
            "2020-03-17 14:12:42,110 epoch 3 - iter 98/140 - loss 11.75929144 - samples/sec: 50.74\n",
            "2020-03-17 14:12:51,014 epoch 3 - iter 112/140 - loss 11.65611655 - samples/sec: 50.37\n",
            "2020-03-17 14:13:01,846 epoch 3 - iter 126/140 - loss 11.69383474 - samples/sec: 41.40\n",
            "2020-03-17 14:13:10,741 epoch 3 - iter 140/140 - loss 11.62322310 - samples/sec: 50.44\n",
            "2020-03-17 14:13:10,750 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:13:10,750 EPOCH 3 done: loss 11.6232 - lr 0.1000\n",
            "2020-03-17 14:13:13,740 DEV : loss 7.270882606506348 - score 0.8957\n",
            "2020-03-17 14:13:13,790 BAD EPOCHS (no improvement): 0\n",
            "2020-03-17 14:13:29,812 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:13:38,850 epoch 4 - iter 14/140 - loss 10.43198115 - samples/sec: 49.58\n",
            "2020-03-17 14:13:47,774 epoch 4 - iter 28/140 - loss 10.56486310 - samples/sec: 50.26\n",
            "2020-03-17 14:13:56,941 epoch 4 - iter 42/140 - loss 10.60153471 - samples/sec: 48.92\n",
            "2020-03-17 14:14:06,032 epoch 4 - iter 56/140 - loss 10.68807687 - samples/sec: 49.33\n",
            "2020-03-17 14:14:18,135 epoch 4 - iter 70/140 - loss 10.69602921 - samples/sec: 37.04\n",
            "2020-03-17 14:14:27,752 epoch 4 - iter 84/140 - loss 10.55558669 - samples/sec: 46.63\n",
            "2020-03-17 14:14:36,898 epoch 4 - iter 98/140 - loss 10.55012274 - samples/sec: 49.03\n",
            "2020-03-17 14:14:45,113 epoch 4 - iter 112/140 - loss 10.39677855 - samples/sec: 54.61\n",
            "2020-03-17 14:14:59,462 epoch 4 - iter 126/140 - loss 10.41176175 - samples/sec: 31.24\n",
            "2020-03-17 14:15:16,349 epoch 4 - iter 140/140 - loss 10.50407050 - samples/sec: 26.55\n",
            "2020-03-17 14:15:16,359 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:15:16,360 EPOCH 4 done: loss 10.5041 - lr 0.1000\n",
            "2020-03-17 14:15:19,393 DEV : loss 6.548562049865723 - score 0.9081\n",
            "2020-03-17 14:15:19,445 BAD EPOCHS (no improvement): 0\n",
            "2020-03-17 14:15:35,301 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:15:47,760 epoch 5 - iter 14/140 - loss 9.68800122 - samples/sec: 36.33\n",
            "2020-03-17 14:16:00,117 epoch 5 - iter 28/140 - loss 10.03906907 - samples/sec: 36.29\n",
            "2020-03-17 14:16:15,691 epoch 5 - iter 42/140 - loss 10.14212402 - samples/sec: 28.79\n",
            "2020-03-17 14:16:24,981 epoch 5 - iter 56/140 - loss 10.11572547 - samples/sec: 48.28\n",
            "2020-03-17 14:16:33,313 epoch 5 - iter 70/140 - loss 9.97087594 - samples/sec: 53.83\n",
            "2020-03-17 14:16:47,786 epoch 5 - iter 84/140 - loss 9.94671723 - samples/sec: 30.98\n",
            "2020-03-17 14:16:57,825 epoch 5 - iter 98/140 - loss 10.01684270 - samples/sec: 44.67\n",
            "2020-03-17 14:17:06,512 epoch 5 - iter 112/140 - loss 9.96552565 - samples/sec: 51.63\n",
            "2020-03-17 14:17:16,744 epoch 5 - iter 126/140 - loss 9.93889559 - samples/sec: 43.83\n",
            "2020-03-17 14:17:25,904 epoch 5 - iter 140/140 - loss 9.90048146 - samples/sec: 48.97\n",
            "2020-03-17 14:17:25,912 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:17:25,913 EPOCH 5 done: loss 9.9005 - lr 0.1000\n",
            "2020-03-17 14:17:28,941 DEV : loss 6.666820049285889 - score 0.9039\n",
            "2020-03-17 14:17:28,992 BAD EPOCHS (no improvement): 1\n",
            "2020-03-17 14:17:28,995 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:17:42,122 epoch 6 - iter 14/140 - loss 9.58735330 - samples/sec: 34.13\n",
            "2020-03-17 14:17:50,417 epoch 6 - iter 28/140 - loss 9.48496142 - samples/sec: 54.10\n",
            "2020-03-17 14:17:59,535 epoch 6 - iter 42/140 - loss 9.54987736 - samples/sec: 49.18\n",
            "2020-03-17 14:18:11,780 epoch 6 - iter 56/140 - loss 9.70516219 - samples/sec: 36.62\n",
            "2020-03-17 14:18:20,484 epoch 6 - iter 70/140 - loss 9.58472402 - samples/sec: 51.53\n",
            "2020-03-17 14:18:29,448 epoch 6 - iter 84/140 - loss 9.50298379 - samples/sec: 50.03\n",
            "2020-03-17 14:18:37,522 epoch 6 - iter 98/140 - loss 9.47060023 - samples/sec: 55.56\n",
            "2020-03-17 14:18:45,862 epoch 6 - iter 112/140 - loss 9.46034771 - samples/sec: 53.79\n",
            "2020-03-17 14:19:00,977 epoch 6 - iter 126/140 - loss 9.43505171 - samples/sec: 29.66\n",
            "2020-03-17 14:19:20,176 epoch 6 - iter 140/140 - loss 9.44773060 - samples/sec: 23.35\n",
            "2020-03-17 14:19:20,186 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:19:20,187 EPOCH 6 done: loss 9.4477 - lr 0.1000\n",
            "2020-03-17 14:19:23,248 DEV : loss 6.148922443389893 - score 0.9137\n",
            "2020-03-17 14:19:23,297 BAD EPOCHS (no improvement): 0\n",
            "2020-03-17 14:19:41,762 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:19:49,021 epoch 7 - iter 14/140 - loss 7.84589539 - samples/sec: 61.74\n",
            "2020-03-17 14:20:04,432 epoch 7 - iter 28/140 - loss 8.76500651 - samples/sec: 29.09\n",
            "2020-03-17 14:20:14,603 epoch 7 - iter 42/140 - loss 9.07290179 - samples/sec: 44.09\n",
            "2020-03-17 14:20:23,903 epoch 7 - iter 56/140 - loss 9.08038148 - samples/sec: 48.22\n",
            "2020-03-17 14:20:36,847 epoch 7 - iter 70/140 - loss 9.12154333 - samples/sec: 34.64\n",
            "2020-03-17 14:20:46,783 epoch 7 - iter 84/140 - loss 9.17094768 - samples/sec: 45.13\n",
            "2020-03-17 14:21:02,603 epoch 7 - iter 98/140 - loss 9.19812605 - samples/sec: 28.34\n",
            "2020-03-17 14:21:12,016 epoch 7 - iter 112/140 - loss 9.22450255 - samples/sec: 47.64\n",
            "2020-03-17 14:21:21,318 epoch 7 - iter 126/140 - loss 9.23942408 - samples/sec: 48.21\n",
            "2020-03-17 14:21:33,577 epoch 7 - iter 140/140 - loss 9.19769365 - samples/sec: 36.57\n",
            "2020-03-17 14:21:33,586 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:21:33,588 EPOCH 7 done: loss 9.1977 - lr 0.1000\n",
            "2020-03-17 14:21:36,683 DEV : loss 6.0934247970581055 - score 0.9121\n",
            "2020-03-17 14:21:36,731 BAD EPOCHS (no improvement): 1\n",
            "2020-03-17 14:21:36,733 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:21:47,563 epoch 8 - iter 14/140 - loss 8.52685462 - samples/sec: 41.38\n",
            "2020-03-17 14:21:56,822 epoch 8 - iter 28/140 - loss 8.69715491 - samples/sec: 48.43\n",
            "2020-03-17 14:22:11,408 epoch 8 - iter 42/140 - loss 8.82535307 - samples/sec: 30.74\n",
            "2020-03-17 14:22:26,293 epoch 8 - iter 56/140 - loss 8.92512832 - samples/sec: 30.12\n",
            "2020-03-17 14:22:37,314 epoch 8 - iter 70/140 - loss 9.02388456 - samples/sec: 40.69\n",
            "2020-03-17 14:22:46,440 epoch 8 - iter 84/140 - loss 9.00717044 - samples/sec: 49.14\n",
            "2020-03-17 14:22:55,425 epoch 8 - iter 98/140 - loss 8.94339539 - samples/sec: 49.91\n",
            "2020-03-17 14:23:10,300 epoch 8 - iter 112/140 - loss 8.92761621 - samples/sec: 30.14\n",
            "2020-03-17 14:23:21,586 epoch 8 - iter 126/140 - loss 8.91410530 - samples/sec: 39.73\n",
            "2020-03-17 14:23:31,888 epoch 8 - iter 140/140 - loss 8.87112515 - samples/sec: 43.53\n",
            "2020-03-17 14:23:31,897 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:23:31,898 EPOCH 8 done: loss 8.8711 - lr 0.1000\n",
            "2020-03-17 14:23:34,950 DEV : loss 5.85880708694458 - score 0.9148\n",
            "2020-03-17 14:23:35,000 BAD EPOCHS (no improvement): 0\n",
            "2020-03-17 14:23:51,500 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:24:00,696 epoch 9 - iter 14/140 - loss 8.45792651 - samples/sec: 48.82\n",
            "2020-03-17 14:24:13,565 epoch 9 - iter 28/140 - loss 8.70351148 - samples/sec: 34.84\n",
            "2020-03-17 14:24:32,103 epoch 9 - iter 42/140 - loss 8.81734049 - samples/sec: 24.18\n",
            "2020-03-17 14:24:43,624 epoch 9 - iter 56/140 - loss 8.85863968 - samples/sec: 38.92\n",
            "2020-03-17 14:24:57,506 epoch 9 - iter 70/140 - loss 8.83394551 - samples/sec: 32.29\n",
            "2020-03-17 14:25:08,733 epoch 9 - iter 84/140 - loss 8.96476130 - samples/sec: 39.94\n",
            "2020-03-17 14:25:18,418 epoch 9 - iter 98/140 - loss 8.84969995 - samples/sec: 46.31\n",
            "2020-03-17 14:25:28,845 epoch 9 - iter 112/140 - loss 8.86813945 - samples/sec: 43.00\n",
            "2020-03-17 14:25:38,740 epoch 9 - iter 126/140 - loss 8.86837404 - samples/sec: 45.32\n",
            "2020-03-17 14:25:49,010 epoch 9 - iter 140/140 - loss 8.82125378 - samples/sec: 43.66\n",
            "2020-03-17 14:25:49,019 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:25:49,020 EPOCH 9 done: loss 8.8213 - lr 0.1000\n",
            "2020-03-17 14:25:52,046 DEV : loss 5.926183700561523 - score 0.915\n",
            "2020-03-17 14:25:52,094 BAD EPOCHS (no improvement): 0\n",
            "2020-03-17 14:26:08,217 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:26:22,822 epoch 10 - iter 14/140 - loss 8.30294701 - samples/sec: 30.69\n",
            "2020-03-17 14:26:33,300 epoch 10 - iter 28/140 - loss 8.39337948 - samples/sec: 42.80\n",
            "2020-03-17 14:26:45,535 epoch 10 - iter 42/140 - loss 8.46550077 - samples/sec: 36.65\n",
            "2020-03-17 14:26:59,904 epoch 10 - iter 56/140 - loss 8.52495140 - samples/sec: 31.20\n",
            "2020-03-17 14:27:14,501 epoch 10 - iter 70/140 - loss 8.64200301 - samples/sec: 30.71\n",
            "2020-03-17 14:27:23,367 epoch 10 - iter 84/140 - loss 8.50199965 - samples/sec: 50.58\n",
            "2020-03-17 14:27:31,808 epoch 10 - iter 98/140 - loss 8.49010673 - samples/sec: 53.14\n",
            "2020-03-17 14:27:45,702 epoch 10 - iter 112/140 - loss 8.56323466 - samples/sec: 32.27\n",
            "2020-03-17 14:27:54,399 epoch 10 - iter 126/140 - loss 8.56414888 - samples/sec: 51.57\n",
            "2020-03-17 14:28:02,371 epoch 10 - iter 140/140 - loss 8.56238954 - samples/sec: 56.27\n",
            "2020-03-17 14:28:02,379 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:28:02,380 EPOCH 10 done: loss 8.5624 - lr 0.1000\n",
            "2020-03-17 14:28:05,393 DEV : loss 5.813287734985352 - score 0.9138\n",
            "2020-03-17 14:28:05,442 BAD EPOCHS (no improvement): 1\n",
            "2020-03-17 14:28:21,442 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-17 14:28:21,651 Testing using best model ...\n",
            "2020-03-17 14:28:21,659 loading file resources/taggers/example-universal-pos/best-model.pt\n",
            "2020-03-17 14:28:58,411 0.9214\t0.9214\t0.9214\n",
            "2020-03-17 14:28:58,412 \n",
            "MICRO_AVG: acc 0.8542 - f1-score 0.9214\n",
            "MACRO_AVG: acc 0.7856 - f1-score 0.8513562499999999\n",
            "ADJ        tp: 304 - fp: 79 - fn: 121 - tn: 304 - precision: 0.7937 - recall: 0.7153 - accuracy: 0.6032 - f1-score: 0.7525\n",
            "ADP        tp: 1116 - fp: 82 - fn: 37 - tn: 1116 - precision: 0.9316 - recall: 0.9679 - accuracy: 0.9036 - f1-score: 0.9494\n",
            "ADV        tp: 391 - fp: 52 - fn: 99 - tn: 391 - precision: 0.8826 - recall: 0.7980 - accuracy: 0.7214 - f1-score: 0.8382\n",
            "AUX        tp: 96 - fp: 1 - fn: 0 - tn: 96 - precision: 0.9897 - recall: 1.0000 - accuracy: 0.9897 - f1-score: 0.9948\n",
            "CCONJ      tp: 333 - fp: 3 - fn: 42 - tn: 333 - precision: 0.9911 - recall: 0.8880 - accuracy: 0.8810 - f1-score: 0.9367\n",
            "DET        tp: 350 - fp: 29 - fn: 24 - tn: 350 - precision: 0.9235 - recall: 0.9358 - accuracy: 0.8685 - f1-score: 0.9296\n",
            "NOUN       tp: 2238 - fp: 232 - fn: 317 - tn: 2238 - precision: 0.9061 - recall: 0.8759 - accuracy: 0.8030 - f1-score: 0.8907\n",
            "NUM        tp: 373 - fp: 22 - fn: 34 - tn: 373 - precision: 0.9443 - recall: 0.9165 - accuracy: 0.8695 - f1-score: 0.9302\n",
            "PART       tp: 43 - fp: 4 - fn: 6 - tn: 43 - precision: 0.9149 - recall: 0.8776 - accuracy: 0.8113 - f1-score: 0.8959\n",
            "PRON       tp: 468 - fp: 17 - fn: 30 - tn: 468 - precision: 0.9649 - recall: 0.9398 - accuracy: 0.9087 - f1-score: 0.9522\n",
            "PROPN      tp: 2085 - fp: 251 - fn: 126 - tn: 2085 - precision: 0.8926 - recall: 0.9430 - accuracy: 0.8469 - f1-score: 0.9171\n",
            "PUNCT      tp: 1723 - fp: 8 - fn: 1 - tn: 1723 - precision: 0.9954 - recall: 0.9994 - accuracy: 0.9948 - f1-score: 0.9974\n",
            "SCONJ      tp: 126 - fp: 50 - fn: 16 - tn: 126 - precision: 0.7159 - recall: 0.8873 - accuracy: 0.6562 - f1-score: 0.7924\n",
            "SYM        tp: 25 - fp: 0 - fn: 5 - tn: 25 - precision: 1.0000 - recall: 0.8333 - accuracy: 0.8333 - f1-score: 0.9091\n",
            "VERB       tp: 1183 - fp: 96 - fn: 67 - tn: 1183 - precision: 0.9249 - recall: 0.9464 - accuracy: 0.8789 - f1-score: 0.9355\n",
            "X          tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "2020-03-17 14:28:58,413 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(13.4746),\n",
              "  tensor(8.7281),\n",
              "  tensor(7.2709),\n",
              "  tensor(6.5486),\n",
              "  tensor(6.6668),\n",
              "  tensor(6.1489),\n",
              "  tensor(6.0934),\n",
              "  tensor(5.8588),\n",
              "  tensor(5.9262),\n",
              "  tensor(5.8133)],\n",
              " 'dev_score_history': [0.808,\n",
              "  0.8708,\n",
              "  0.8957,\n",
              "  0.9081,\n",
              "  0.9039,\n",
              "  0.9137,\n",
              "  0.9121,\n",
              "  0.9148,\n",
              "  0.915,\n",
              "  0.9138],\n",
              " 'test_score': 0.9214,\n",
              " 'train_loss_history': [31.46200088092259,\n",
              "  14.518376234599522,\n",
              "  11.623223100389753,\n",
              "  10.504070499965122,\n",
              "  9.900481455666679,\n",
              "  9.447730599130903,\n",
              "  9.197693647657122,\n",
              "  8.871125146320887,\n",
              "  8.821253776550293,\n",
              "  8.562389544078282]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMY2WZEX0QSW",
        "colab_type": "code",
        "outputId": "671f856e-2543-4627-ca62-a4c2400977ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "sentence = Sentence('saya dan dia kemarin pergi ke pasar bersama untuk membeli jeruk')\n",
        "tag_pos = SequenceTagger.load('resources/taggers/example-universal-pos/best-model.pt')\n",
        "tag_pos.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-17 14:29:11,129 loading file resources/taggers/example-universal-pos/best-model.pt\n",
            "saya <PRON> dan <CCONJ> dia <PRON> kemarin <ADV> pergi <VERB> ke <ADP> pasar <NOUN> bersama <ADP> untuk <ADP> membeli <VERB> jeruk <NOUN>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}